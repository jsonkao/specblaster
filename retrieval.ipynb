{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Documents\n",
    "\n",
    "The Reuters-21578 files are in [SGML format](http://kdd.ics.uci.edu/databases/reuters21578/README.txt). We need to split them into individual documents. There should be 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/reut2-000.sgm') as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(corpus, 'html.parser')\n",
    "allArticles = soup.find_all('reuters')\n",
    "\n",
    "articles = [] # stories with a body\n",
    "documents = []\n",
    "for a in allArticles:\n",
    "    if a.body:\n",
    "        articles.append(a)\n",
    "        documents.append(re.split('\\W+', a.body.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'asdf', 'asdf']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('\\s', 'asdf asdf\\nasdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Showers',\n",
       " 'continued',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'week',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Bahia',\n",
       " 'cocoa',\n",
       " 'zone',\n",
       " 'alleviating',\n",
       " 'the',\n",
       " 'drought',\n",
       " 'since',\n",
       " 'early',\n",
       " 'January',\n",
       " 'and',\n",
       " 'improving',\n",
       " 'prospects',\n",
       " 'for',\n",
       " 'the',\n",
       " 'coming',\n",
       " 'temporao',\n",
       " 'although',\n",
       " 'normal',\n",
       " 'humidity',\n",
       " 'levels',\n",
       " 'have',\n",
       " 'not',\n",
       " 'been',\n",
       " 'restored',\n",
       " 'Comissaria',\n",
       " 'Smith',\n",
       " 'said',\n",
       " 'in',\n",
       " 'its',\n",
       " 'weekly',\n",
       " 'review',\n",
       " 'The',\n",
       " 'dry',\n",
       " 'period',\n",
       " 'means',\n",
       " 'the',\n",
       " 'temporao',\n",
       " 'will',\n",
       " 'be',\n",
       " 'late',\n",
       " 'this',\n",
       " 'year',\n",
       " 'Arrivals',\n",
       " 'for',\n",
       " 'the',\n",
       " 'week',\n",
       " 'ended',\n",
       " 'February',\n",
       " '22',\n",
       " 'were',\n",
       " '155',\n",
       " '221',\n",
       " 'bags',\n",
       " 'of',\n",
       " '60',\n",
       " 'kilos',\n",
       " 'making',\n",
       " 'a',\n",
       " 'cumulative',\n",
       " 'total',\n",
       " 'for',\n",
       " 'the',\n",
       " 'season',\n",
       " 'of',\n",
       " '5',\n",
       " '93',\n",
       " 'mln',\n",
       " 'against',\n",
       " '5',\n",
       " '81',\n",
       " 'at',\n",
       " 'the',\n",
       " 'same',\n",
       " 'stage',\n",
       " 'last',\n",
       " 'year',\n",
       " 'Again',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'that',\n",
       " 'cocoa',\n",
       " 'delivered',\n",
       " 'earlier',\n",
       " 'on',\n",
       " 'consignment',\n",
       " 'was',\n",
       " 'included',\n",
       " 'in',\n",
       " 'the',\n",
       " 'arrivals',\n",
       " 'figures',\n",
       " 'Comissaria',\n",
       " 'Smith',\n",
       " 'said',\n",
       " 'there',\n",
       " 'is',\n",
       " 'still',\n",
       " 'some',\n",
       " 'doubt',\n",
       " 'as',\n",
       " 'to',\n",
       " 'how',\n",
       " 'much',\n",
       " 'old',\n",
       " 'crop',\n",
       " 'cocoa',\n",
       " 'is',\n",
       " 'still',\n",
       " 'available',\n",
       " 'as',\n",
       " 'harvesting',\n",
       " 'has',\n",
       " 'practically',\n",
       " 'come',\n",
       " 'to',\n",
       " 'an',\n",
       " 'end',\n",
       " 'With',\n",
       " 'total',\n",
       " 'Bahia',\n",
       " 'crop',\n",
       " 'estimates',\n",
       " 'around',\n",
       " '6',\n",
       " '4',\n",
       " 'mln',\n",
       " 'bags',\n",
       " 'and',\n",
       " 'sales',\n",
       " 'standing',\n",
       " 'at',\n",
       " 'almost',\n",
       " '6',\n",
       " '2',\n",
       " 'mln',\n",
       " 'there',\n",
       " 'are',\n",
       " 'a',\n",
       " 'few',\n",
       " 'hundred',\n",
       " 'thousand',\n",
       " 'bags',\n",
       " 'still',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hands',\n",
       " 'of',\n",
       " 'farmers',\n",
       " 'middlemen',\n",
       " 'exporters',\n",
       " 'and',\n",
       " 'processors',\n",
       " 'There',\n",
       " 'are',\n",
       " 'doubts',\n",
       " 'as',\n",
       " 'to',\n",
       " 'how',\n",
       " 'much',\n",
       " 'of',\n",
       " 'this',\n",
       " 'cocoa',\n",
       " 'would',\n",
       " 'be',\n",
       " 'fit',\n",
       " 'for',\n",
       " 'export',\n",
       " 'as',\n",
       " 'shippers',\n",
       " 'are',\n",
       " 'now',\n",
       " 'experiencing',\n",
       " 'dificulties',\n",
       " 'in',\n",
       " 'obtaining',\n",
       " 'Bahia',\n",
       " 'superior',\n",
       " 'certificates',\n",
       " 'In',\n",
       " 'view',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lower',\n",
       " 'quality',\n",
       " 'over',\n",
       " 'recent',\n",
       " 'weeks',\n",
       " 'farmers',\n",
       " 'have',\n",
       " 'sold',\n",
       " 'a',\n",
       " 'good',\n",
       " 'part',\n",
       " 'of',\n",
       " 'their',\n",
       " 'cocoa',\n",
       " 'held',\n",
       " 'on',\n",
       " 'consignment',\n",
       " 'Comissaria',\n",
       " 'Smith',\n",
       " 'said',\n",
       " 'spot',\n",
       " 'bean',\n",
       " 'prices',\n",
       " 'rose',\n",
       " 'to',\n",
       " '340',\n",
       " 'to',\n",
       " '350',\n",
       " 'cruzados',\n",
       " 'per',\n",
       " 'arroba',\n",
       " 'of',\n",
       " '15',\n",
       " 'kilos',\n",
       " 'Bean',\n",
       " 'shippers',\n",
       " 'were',\n",
       " 'reluctant',\n",
       " 'to',\n",
       " 'offer',\n",
       " 'nearby',\n",
       " 'shipment',\n",
       " 'and',\n",
       " 'only',\n",
       " 'limited',\n",
       " 'sales',\n",
       " 'were',\n",
       " 'booked',\n",
       " 'for',\n",
       " 'March',\n",
       " 'shipment',\n",
       " 'at',\n",
       " '1',\n",
       " '750',\n",
       " 'to',\n",
       " '1',\n",
       " '780',\n",
       " 'dlrs',\n",
       " 'per',\n",
       " 'tonne',\n",
       " 'to',\n",
       " 'ports',\n",
       " 'to',\n",
       " 'be',\n",
       " 'named',\n",
       " 'New',\n",
       " 'crop',\n",
       " 'sales',\n",
       " 'were',\n",
       " 'also',\n",
       " 'light',\n",
       " 'and',\n",
       " 'all',\n",
       " 'to',\n",
       " 'open',\n",
       " 'ports',\n",
       " 'with',\n",
       " 'June',\n",
       " 'July',\n",
       " 'going',\n",
       " 'at',\n",
       " '1',\n",
       " '850',\n",
       " 'and',\n",
       " '1',\n",
       " '880',\n",
       " 'dlrs',\n",
       " 'and',\n",
       " 'at',\n",
       " '35',\n",
       " 'and',\n",
       " '45',\n",
       " 'dlrs',\n",
       " 'under',\n",
       " 'New',\n",
       " 'York',\n",
       " 'july',\n",
       " 'Aug',\n",
       " 'Sept',\n",
       " 'at',\n",
       " '1',\n",
       " '870',\n",
       " '1',\n",
       " '875',\n",
       " 'and',\n",
       " '1',\n",
       " '880',\n",
       " 'dlrs',\n",
       " 'per',\n",
       " 'tonne',\n",
       " 'FOB',\n",
       " 'Routine',\n",
       " 'sales',\n",
       " 'of',\n",
       " 'butter',\n",
       " 'were',\n",
       " 'made',\n",
       " 'March',\n",
       " 'April',\n",
       " 'sold',\n",
       " 'at',\n",
       " '4',\n",
       " '340',\n",
       " '4',\n",
       " '345',\n",
       " 'and',\n",
       " '4',\n",
       " '350',\n",
       " 'dlrs',\n",
       " 'April',\n",
       " 'May',\n",
       " 'butter',\n",
       " 'went',\n",
       " 'at',\n",
       " '2',\n",
       " '27',\n",
       " 'times',\n",
       " 'New',\n",
       " 'York',\n",
       " 'May',\n",
       " 'June',\n",
       " 'July',\n",
       " 'at',\n",
       " '4',\n",
       " '400',\n",
       " 'and',\n",
       " '4',\n",
       " '415',\n",
       " 'dlrs',\n",
       " 'Aug',\n",
       " 'Sept',\n",
       " 'at',\n",
       " '4',\n",
       " '351',\n",
       " 'to',\n",
       " '4',\n",
       " '450',\n",
       " 'dlrs',\n",
       " 'and',\n",
       " 'at',\n",
       " '2',\n",
       " '27',\n",
       " 'and',\n",
       " '2',\n",
       " '28',\n",
       " 'times',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Sept',\n",
       " 'and',\n",
       " 'Oct',\n",
       " 'Dec',\n",
       " 'at',\n",
       " '4',\n",
       " '480',\n",
       " 'dlrs',\n",
       " 'and',\n",
       " '2',\n",
       " '27',\n",
       " 'times',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Dec',\n",
       " 'Comissaria',\n",
       " 'Smith',\n",
       " 'said',\n",
       " 'Destinations',\n",
       " 'were',\n",
       " 'the',\n",
       " 'U',\n",
       " 'S',\n",
       " 'Covertible',\n",
       " 'currency',\n",
       " 'areas',\n",
       " 'Uruguay',\n",
       " 'and',\n",
       " 'open',\n",
       " 'ports',\n",
       " 'Cake',\n",
       " 'sales',\n",
       " 'were',\n",
       " 'registered',\n",
       " 'at',\n",
       " '785',\n",
       " 'to',\n",
       " '995',\n",
       " 'dlrs',\n",
       " 'for',\n",
       " 'March',\n",
       " 'April',\n",
       " '785',\n",
       " 'dlrs',\n",
       " 'for',\n",
       " 'May',\n",
       " '753',\n",
       " 'dlrs',\n",
       " 'for',\n",
       " 'Aug',\n",
       " 'and',\n",
       " '0',\n",
       " '39',\n",
       " 'times',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Dec',\n",
       " 'for',\n",
       " 'Oct',\n",
       " 'Dec',\n",
       " 'Buyers',\n",
       " 'were',\n",
       " 'the',\n",
       " 'U',\n",
       " 'S',\n",
       " 'Argentina',\n",
       " 'Uruguay',\n",
       " 'and',\n",
       " 'convertible',\n",
       " 'currency',\n",
       " 'areas',\n",
       " 'Liquor',\n",
       " 'sales',\n",
       " 'were',\n",
       " 'limited',\n",
       " 'with',\n",
       " 'March',\n",
       " 'April',\n",
       " 'selling',\n",
       " 'at',\n",
       " '2',\n",
       " '325',\n",
       " 'and',\n",
       " '2',\n",
       " '380',\n",
       " 'dlrs',\n",
       " 'June',\n",
       " 'July',\n",
       " 'at',\n",
       " '2',\n",
       " '375',\n",
       " 'dlrs',\n",
       " 'and',\n",
       " 'at',\n",
       " '1',\n",
       " '25',\n",
       " 'times',\n",
       " 'New',\n",
       " 'York',\n",
       " 'July',\n",
       " 'Aug',\n",
       " 'Sept',\n",
       " 'at',\n",
       " '2',\n",
       " '400',\n",
       " 'dlrs',\n",
       " 'and',\n",
       " 'at',\n",
       " '1',\n",
       " '25',\n",
       " 'times',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Sept',\n",
       " 'and',\n",
       " 'Oct',\n",
       " 'Dec',\n",
       " 'at',\n",
       " '1',\n",
       " '25',\n",
       " 'times',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Dec',\n",
       " 'Comissaria',\n",
       " 'Smith',\n",
       " 'said',\n",
       " 'Total',\n",
       " 'Bahia',\n",
       " 'sales',\n",
       " 'are',\n",
       " 'currently',\n",
       " 'estimated',\n",
       " 'at',\n",
       " '6',\n",
       " '13',\n",
       " 'mln',\n",
       " 'bags',\n",
       " 'against',\n",
       " 'the',\n",
       " '1986',\n",
       " '87',\n",
       " 'crop',\n",
       " 'and',\n",
       " '1',\n",
       " '06',\n",
       " 'mln',\n",
       " 'bags',\n",
       " 'against',\n",
       " 'the',\n",
       " '1987',\n",
       " '88',\n",
       " 'crop',\n",
       " 'Final',\n",
       " 'figures',\n",
       " 'for',\n",
       " 'the',\n",
       " 'period',\n",
       " 'to',\n",
       " 'February',\n",
       " '28',\n",
       " 'are',\n",
       " 'expected',\n",
       " 'to',\n",
       " 'be',\n",
       " 'published',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Brazilian',\n",
       " 'Cocoa',\n",
       " 'Trade',\n",
       " 'Commission',\n",
       " 'after',\n",
       " 'carnival',\n",
       " 'which',\n",
       " 'ends',\n",
       " 'midday',\n",
       " 'on',\n",
       " 'February',\n",
       " '27',\n",
       " 'Reuter',\n",
       " '']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn each document into a vector of W dimensions, where W is the number of words in the corpus. Each component of the vector represents the term frequency inverse document frequency (TF-IDF) of one word in the document. TF-IDF is a weighting scheme based on a word's occurrence in a document (term frequency) and its uniqueness in the overall corpus (inverse document frequency). A higher TF-IDF usually means the word is more important in the corpus.\n",
    "\n",
    "There are [several different weighting schemes](https://en.wikipedia.org/wiki/Tf%E2%80%93idf#Definition) we could use; the ones I've chosen are as follows. \n",
    "\n",
    "For term frequency (tf) we will use a type of weighting scheme called [double normalization](https://nlp.stanford.edu/IR-book/html/htmledition/maximum-tf-normalization-1.html). The first normalization divides a word's raw count by the maximum raw count of a word in that document. This prevents TF's bias towards longer documents. Then we normalize again by \"smoothing\", which prevents modest changes in tf from greatly affecting TF-IDF.\n",
    "\n",
    "For inverse document frequency (idf) we will use the standard logarithmically scaled frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "$$ tf = 0.4 + (1-0.4)\\frac{N(v_i, d)}{max_{v_j \\in s}N(v_j, d)} $$\n",
       "\n",
       "where $N(v_i, s)$ is the number of times word $v_i$ occurs in document $d$. We've used the common smoothing constant of 0.4.\n",
       "\n",
       "$$ idf = log \\frac{N}{N(v_i)} $$\n",
       "\n",
       "where $N$ is the number of documents in the corpus, and $N(v_i)$ is the number of documents that includes $v_i$.\n",
       "\n",
       "$$ TF\\text{-}IDF = tf \\times idf $$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\n",
    "$$ tf = 0.4 + (1-0.4)\\frac{N(v_i, d)}{max_{v_j \\in s}N(v_j, d)} $$\n",
    "\n",
    "where $N(v_i, s)$ is the number of times word $v_i$ occurs in document $d$. We've used the common smoothing constant of 0.4.\n",
    "\n",
    "$$ idf = log \\frac{N}{N(v_i)} $$\n",
    "\n",
    "where $N$ is the number of documents in the corpus, and $N(v_i)$ is the number of documents that includes $v_i$.\n",
    "\n",
    "$$ TF\\text{-}IDF = tf \\times idf $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11234 unique words over 925 documents.\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for doc in documents:\n",
    "    words += doc\n",
    "words = [w for w in set(words) if len(w) > 0]\n",
    "numWords = len(words)\n",
    "\n",
    "print('There are {} unique words over {} documents.'.format(numWords, len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToLoc = {words[i]: i for i in range(numWords)} # a word to index lookup\n",
    "\n",
    "# stores number of documents a word appears in\n",
    "documentCounts = [0 for _ in range(numWords)]\n",
    "\n",
    "a = 0.4 # our smoothing constant\n",
    "\n",
    "# Calculates tf vector while building document counts\n",
    "def tf(doc):    \n",
    "    vector = [0 for _ in range(numWords)]\n",
    "    counted = defaultdict(bool) # keeps track of if we've counted the word towards document frequency\n",
    "    for word in doc:\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "        loc = wordToLoc[word]\n",
    "        vector[loc] += 1\n",
    "        if not counted[word]:\n",
    "            documentCounts[loc] += 1\n",
    "            counted[word] = True\n",
    "    maxTf = max(vector)\n",
    "    return [a + (1 - a) * c / maxTf for c in vector]\n",
    "\n",
    "tfVectors = [tf(d) for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfCache = {}\n",
    "def getIdf(i):\n",
    "    if i not in idfCache:\n",
    "        idfCache[i] = math.log10(len(documents) / documentCounts[i])\n",
    "    return idfCache[i]\n",
    "\n",
    "def normalizeByIdf(vector):\n",
    "    output = []\n",
    "    for i in range(len(vector)):\n",
    "        output.append(vector[i] * getIdf(i))\n",
    "    return output\n",
    "            \n",
    "tfidf = [normalizeByIdf(v) for v in tfVectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
